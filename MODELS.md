# 🧠 Installed Coding LLMs — BLUX-Lite

## 🔤 Model: codegemma
- Optimized for code synthesis
- Fast, lightweight, small RAM footprint
- Best for JS, Python, HTML, CLI tasks

## 🤖 Model: phi3
- Microsoft compact model
- Handles general-purpose tasks + coding
- Good balance for Android devices

## 🦙 Model: llama3
- Meta’s state-of-the-art open LLM
- Handles longer context, more creative responses
- Requires more RAM (6–8 GB)

## 🌪️ Model: mistral
- Fast, robust, multilingual
- Great fallback or general-purpose model

---

## Tip: To switch model in `llama_chat.py`, edit:
```python
MODEL = "mistral"

Then run:

python3 llama_chat.py

