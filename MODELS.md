# ğŸ§  Installed Coding LLMs â€” BLUX-Lite

## ğŸ”¤ Model: codegemma
- Optimized for code synthesis
- Fast, lightweight, small RAM footprint
- Best for JS, Python, HTML, CLI tasks

## ğŸ¤– Model: phi3
- Microsoft compact model
- Handles general-purpose tasks + coding
- Good balance for Android devices

## ğŸ¦™ Model: llama3
- Metaâ€™s state-of-the-art open LLM
- Handles longer context, more creative responses
- Requires more RAM (6â€“8 GB)

## ğŸŒªï¸ Model: mistral
- Fast, robust, multilingual
- Great fallback or general-purpose model

---

## Tip: To switch model in `llama_chat.py`, edit:
```python
MODEL = "mistral"

Then run:

python3 llama_chat.py

